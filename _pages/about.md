---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Zhou Feng, graduated from the State Key Laboratory of Virtual Reality Technology and Systems at Beihang University, under the supervision of Professors Shen Xukun and Hu Yong. In 2020, he joined the School of Information Science and Technology at North Industrial University as a lecturer.<br/>

My research focuses on 3D computer vision, artificial intelligence, and virtual reality, specifically in the areas of point cloud segmentation, point cloud detection, and digital human modeling and understanding. Additionally, I am actively exploring applications in virtual reality and the protection of intangible cultural heritage, such as choreography for intangible cultural dances and content generation. I have led one project supported by the Beijing Natural Science Foundation, one project under the Beijing Municipal Education Commission Science and Technology Plan, one sub-project under the Yunnan Provincial Science and Technology Plan, and one open project of the State Key Laboratory. I have published over 10 papers in the fields of computer graphics and artificial intelligence. Furthermore, I am a member of various committees, including the Virtual Reality and Visualization Technology Professional Committee of the China Computer Society, the Virtual Technology and Application Professional Committee of the China Simulation Society, the Virtual Space Special Committee of the China Film Art Society, and the Digital Media Special Committee of the China Graphics Society.

Currently, I collaborate closely with Beihang University, Peng Cheng Laboratory, and Cardiff University.
Looking forward to students who are interested in the research direction, and willing to proactively engage with the supervisor's research,
Let's embark on the academic journey towards "A" together, and have a blast!
Let's go all out and have fun together on this academic journey!

# üéì News
- *2024.05* </a> One paper is accepted to TVC
- *2024.02* </a> One paper FormationCreator is accepted to LBW CHI2024
- *2023.12* </a> One paper AHRNet is accepted to ICASSP2024
- *2023.11* </a> One paper KD-Former is accepted to Pattern Recognition
 

# üìù Publications 


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Applied Sciences 13,</div><img src='images/freeEdit.png' alt="png" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

-	lin, Y., Dai, J., Pan, J., `Zhou, F.`, & Bai, J. (2024). Free editing of Shape and Texture with Deformable Net for 3D Caricature Generation. The Visual Computer, 1-13.
[[ÁΩëÈ°µ]](https://link.springer.com/article/10.1007/s00371-024-03461-9) 

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Applied Sciences 13</div><img src='images/formationCreator.gif' alt="png" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

-	 Rao J, `Zhou F`, Dai J, et al. FormationCreator: Designing A VR Dance Formation System for Intangible Cultural Heritage Dance[C]//Extended Abstracts of the CHI Conference on Human Factors in Computing Systems. 2024: 1-7.
[[ÁΩëÈ°µ]](https://dl.acm.org/doi/full/10.1145/3613905.3651028)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">The Visual Computer, 2019</div><img src='images/AHNet.gif' alt="png" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

-	`Zhou F`, Shen P, Dai J, et al. AHRNet: Attention and heatmap-based regressor for hand pose estimation and mesh recovery[C]//ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2024: 3000-3004.
[[ÁΩëÈ°µ]](https://ieeexplore.ieee.org/abstract/document/10446600/)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Applied Sciences 13,</div><img src='images/KD.png' alt="png" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

-	Dai, J., Li, H., Zeng, R., Bai, J., `Zhou, F.`, & Pan, J. (2023). KD-Former: Kinematic and dynamic coupled transformer network for 3D human motion prediction. Pattern Recognition, 143, 109806.
[[ÁΩëÈ°µ]](https://www.sciencedirect.com/science/article/abs/pii/S0031320323005046) 

</div>
</div>

- Chen, Keng, `Feng Zhou`, Ju Dai, Pei Shen, Xingquan Cai, and Fengquan Zhang. "MCGNet: Multi-Level Context-aware and Geometric-aware Network for 3D Object Detection." In 2022 IEEE International Conference on Image Processing (ICIP), pp. 1846-1850. IEEE, 2022.  
[[HEML]](https://ieeexplore.ieee.org/abstract/document/9897465/)


- `F Zhou`, J Dai, J Pan, M Zhu, X Cai, B Huang, C Wang, GFENet: Group-Free Enhancement Network for Indoor Scene 3D Object Detection, COMPUTER GRAPHICS INTERNATIONAL 2023 
[[HEML]](https://link.springer.com/chapter/10.1007/978-3-031-50075-6_10)

- `Zhou, Feng`, Junkai Rao, Pei Shen, Qi Zhang, Qianfang Qi, and Yao Li. "REGNet: Ray-Based Enhancement Grouping for 3D Object Detection Based on Point Cloud." Applied Sciences 13, no. 10 (2023): 6098.
[[HEML]](https://www.mdpi.com/2076-3417/13/10/6098)

- `Zhou, Feng`, Yu-Kun Lai, Paul L. Rosin, Fengquan Zhang, and Yong Hu. "Scale-aware network with modality-awareness for RGB-D indoor semantic segmentation." Neurocomputing 492 (2022): 464-473.
[[HEML]](https://www.sciencedirect.com/science/article/abs/pii/S0925231222003903)

- `Zhou F`, Hu Y, Shen X. Scale-aware spatial pyramid pooling with both encoder-mask and scale-attention for semantic segmentation[J]. Neurocomputing, 2020, 383: 174-182.
[[HEML]](https://www.sciencedirect.com/science/article/abs/pii/S0925231219316443)

- Dyke R M, `Zhou F`, Lai Y, et al. SHREC'20: Non-rigid shape correspondence of physically-based deformations[J]. 2020.  
[[HEML]](https://orca.cardiff.ac.uk/id/eprint/134585/)

-You can refer to it directly: https://scholar.google.com.hk/citations?user=Ad1_iFMAAAAJ&hl=zh-CN

<span class='anchor' id='-ryjx'></span>




# üèÖ Students awards
- *2023* Two first prizes in CCVR2023, One two prize in CCVR2023
- *2022* Two first prizes in CCVR2022, one third prize in CCVR2022

# üí¨ Course

- Virtual Reality
- Software Engineering


  
